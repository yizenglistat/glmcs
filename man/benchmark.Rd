% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/benchmark.R
\name{benchmark}
\alias{benchmark}
\title{Benchmark Variable Selection Methods}
\usage{
benchmark(
  n_sims = 50,
  simulate_control = list(),
  methods = c("glmcs", "susie"),
  glmcs_control = list(),
  susie_control = list(),
  parallel = FALSE,
  cores = parallel::detectCores() - 1,
  save_path = NULL,
  save_freq = 50,
  progress = TRUE
)
}
\arguments{
\item{n_sims}{Integer. Number of simulation replicates. Default: 50.}

\item{simulate_control}{List. Arguments forwarded to \code{\link{simulate}()},
must include at least \code{n}, \code{p}, \code{family}, \code{settings}.}

\item{methods}{Character vector. Methods to evaluate: \code{"glmcs"}, \code{"susie"}.
Default: c("glmcs", "susie"). Note: SuSiE works with Gaussian family only.}

\item{glmcs_control}{List. Arguments forwarded to \code{\link{glmcs}()}.
Default parameters include L=10, coverage=0.95, standardize=TRUE, etc.}

\item{susie_control}{List. Arguments forwarded to \code{susieR::susie()}.
Default parameters include L=10, max_iter=1000, etc.}

\item{parallel}{Logical. Whether to run simulations in parallel. Default: FALSE.}

\item{cores}{Integer. Number of parallel workers if parallel=TRUE.
Default: parallel::detectCores() - 1.}

\item{save_path}{Character or NULL. Path to save intermediate results.
If provided, results are saved every save_freq iterations. Default: NULL.}

\item{save_freq}{Integer. How often to save intermediate results. Default: 50.}

\item{progress}{Logical or character. Progress tracking method:
\itemize{
\item TRUE or "bar": Progress bar (requires 'progress' package)
\item "text": Text-based updates
\item FALSE: No progress reporting
Default: TRUE.
}}
}
\value{
A list with components:
\describe{
\item{\code{coef_summary}}{List of data frames (one per method) summarizing coefficient recovery.}
\item{\code{cs_summary}}{List of data frames (one per method) summarizing confidence sets.}
\item{\code{cover_summary}}{List of coverage rates (one value per method).}
\item{\code{elapsed_time}}{Total benchmark execution time.}
\item{\code{methods_used}}{Character vector of methods actually used.}
}
}
\description{
Run comparative simulations to evaluate multiple variable selection methods
on their ability to recover true coefficients and construct valid confidence sets.
The framework automatically handles method compatibility with different response types.
}
\details{
This function performs the following steps for each simulation replicate:
\enumerate{
\item Generate synthetic data via \code{\link{simulate}()} with controlled correlation structure
\item Fit each compatible method to the same data:
\itemize{
\item \strong{glmcs}: LASER algorithm for all GLM families and Cox models
\item \strong{susie}: Sum of Single Effects for Gaussian responses only
}
\item Collect and evaluate results on:
\itemize{
\item Coefficient recovery (bias, variance)
\item Confidence set construction (frequency, coverage)
}
}

The benchmark supports progress tracking and parallel execution for faster evaluation
of large simulation studies. Results are saved periodically if requested.
}
\examples{
\dontrun{
# Gaussian example (both glmcs and susie compatible)
sim_ctrl <- list(
  n = 200,
  p = 20,
  family = gaussian(),
  settings = "ex1",
  control = list(intercept = 1, dispersion = 2, rho = 0.8)
)

# Run with default settings
results <- benchmark(
  n_sims = 50,
  simulate_control = sim_ctrl,
  methods = c("glmcs", "susie")
)

# Extract performance metrics
print(results$coef_summary$glmcs)
print(results$cover_summary)

# Binomial example (only glmcs compatible)
sim_logit <- list(
  n = 200,
  p = 10,
  family = binomial(),
  settings = "ex1"
)

# Run with parallel processing
logit_results <- benchmark(
  n_sims = 100,
  simulate_control = sim_logit,
  methods = "glmcs",
  parallel = TRUE,
  cores = 4
)
}

}
